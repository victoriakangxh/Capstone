# BT4103 Group 4 - Data driven Customer Behavior Analysis in F&B

Our capstone project is centered around assisting our client, SicPama Co., Ltd. (South Korea) and SicPama Pte. Ltd. (Singapore), in executing a Data-Driven Customer Behaviour Analysis within the Food & Beverage sector. We have successfully engineered a robust pipeline, utilizing Apache Airflow, that autonomously retrieves data from the designated source and updates our visual representations. These visualizations have been crafted using Google Looker, a tool renowned for its interactive and insightful dashboards. The dashboard, generated by Google Looker, encapsulates our comprehensive analysis of customer behaviors, focusing on key metrics such as attrition rates and engagement durations. This serves as the executive summary for our final report.

## Main folder Overview
- **src folder**: Contains jupyter notebooks of visualisations and hypothesis testing. 
    - **Visualisations.ipynb**: Includes the data visualizations requested by the client.
    - **EngagementTimeByTransitBtns.ipynb**: Entails the hypothesis testing comparing the average engagement time spent on transition buttons during failed sessions to successful sessions.
    - **ScrollingTimeHypothesis.ipynb**: Entails the hypothesis test of average engagement time spent on scrolling Sicpama's ordering menu.
- **airflow_proj folder**: This directory holds all the necessary files essential for running Airflow Docker.
- **data folder**: This folder contains our Google Analytics data and SQL data.
    - **ga_data.csv**: Combined dataset containing both Google Analytics and SQL data, utilized in Jupyter notebooks for visualizations and hypothesis testing purposes.
    - **query_order_status_24-02-27.csv**: SQL Data of customer orders and transactions up to 27 Feb 2024.
    - **session_user_count_query_24-02-27.csv**: SQL Data of customer orders up to 27 Feb 2024.
    - ** SicPama Google Analytics dataset.json**: Json Data of customer interactions on Sicpama's website.
- **Pipeline Instructions pdf**: Instructions to running pipeline

### airflow_proj folder
- **.googlecloud**: Includes our google credentials
- **dags**: Contains Python files utilized within the pipeline.
    - **helpers folder**: Consists of Python files containing transformation logic and helper functions for pipeline
    - **backup_dag.py**: Back up script responsible for extracting data from Google Cloud Storage and executing the data transformation process.
    - **bigquery_migration_dag.py**: Script facilitating the connection to Google BigQuery.
    - **constants.py**: Repository of constant variables 
    - **main_etl_dag.py**: Main script responsible for extracting data from Google Cloud Storage and executing the data transformation process.

### Google Looker Dashboard
https://lookerstudio.google.com/s/hlu_Bk-3Rnc


